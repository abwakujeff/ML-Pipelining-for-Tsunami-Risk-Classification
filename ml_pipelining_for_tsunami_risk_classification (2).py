# -*- coding: utf-8 -*-
"""ML Pipelining for Tsunami Risk Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RwXAlM7vrtGmbAwxlQ9xImZC3zFoEJpY
"""

# Install required packages
!pip install lazypredict shap

# Core data handling
import numpy as np
import pandas as pd

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Scikit-learn for ML pipeline
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (confusion_matrix, ConfusionMatrixDisplay,
                            classification_report, accuracy_score, f1_score)

# Model evaluation and selection
from lazypredict.Supervised import LazyClassifier

# Model interpretation
import shap

# Utilities
import warnings
warnings.filterwarnings('ignore')

# Set better plotting style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
print("All packages imported successfully!")

# Load the dataset
PATH = '/content/earthquake_data_tsunami.csv'
RECORDS = pd.read_csv(PATH)

# Display basic information about the dataset
print("Dataset Shape:", RECORDS.shape)
print("\nFirst 5 rows:")
RECORDS.head()

# Get more detailed information about the dataset
print("Dataset Info:")
print(RECORDS.info())

# Check for missing values
print("Missing Values:")
missing_data = RECORDS.isnull().sum()
print(missing_data[missing_data > 0])

